{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('21st_year_bert-base-uncased_syntactic_complexity_L-inf.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    vec_file = [row for row in reader]\n",
    "    vec_head = vec_file[0]\n",
    "    vec_text = vec_file[1:]\n",
    "vecs  = [[float(element) for element in row[vec_head.index('attention_heads_Linf_vector')][1:-1].split(', ')] \\\n",
    "         if row[vec_head.index('attention_heads_Linf_vector')] != '' else [] for row in vec_text]\n",
    "vec_ids = [len(vec)==144 for vec in vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/21st_year/tr_tokens_new.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    ling_file = [row for row in reader]\n",
    "    ling_head = ling_file[0]\n",
    "    ling_text = ling_file[1:]\n",
    "features = [[element[1:-1] for element in row[ling_head.index('dep_rel')][1:-1].split(', ')]\\\n",
    "           if len(row[ling_head.index('dep_rel')]) >0 else [] for row in ling_text]\n",
    "feature_ids = [feature[0] != '' for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [vec_id and feature_id for vec_id, feature_id in zip(vec_ids,feature_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vecs = np.array([vec for element,vec in zip(ids,vecs) if element])\n",
    "new_features = [feature for element,feature in zip(ids,features) if element]\n",
    "assert new_vecs.shape[0] == len(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLabels(new_features,label):\n",
    "    return np.array([1 if label in feature else 0 for feature in new_features])\n",
    "def MyCrossValidation(X,y,model,verbose,cv):\n",
    "    assert X.shape[0] == y.shape[0], 'Shape mismatch between X and y; make sure both are np arrays'\n",
    "    random_ids = np.random.permutation(X.shape[0])\n",
    "    batch_size = X.shape[0] // cv\n",
    "    scores = []\n",
    "    params= []\n",
    "    for i in range(cv):\n",
    "        if i == cv-1:\n",
    "            test_ids = random_ids[batch_size*i:]\n",
    "        else:\n",
    "            test_ids = random_ids[batch_size*i:batch_size*(i+1)]\n",
    "        train_ids = np.array([element for element in random_ids if element not in test_ids])\n",
    "        assert len(test_ids) +  len(train_ids) == X.shape[0]\n",
    "        train_X = X[train_ids]\n",
    "        test_X = X[test_ids]\n",
    "        train_y = y[train_ids]\n",
    "        test_y = y[test_ids]\n",
    "        model.fit(train_X,train_y)\n",
    "        scores.append(model.score(test_X,test_y))\n",
    "        assert scores[-1] == np.mean(model.predict(test_X)==test_y)\n",
    "        params.append(model.coef_[0])\n",
    "        if verbose:\n",
    "            print([ConvertHeadNotation(head_num) for head_num in params[-1].argsort()[::-1][:5]])\n",
    "    return scores,np.array(params)\n",
    "def ConvertHeadNotation(head_num):\n",
    "    return f'{head_num//12+1}-{head_num%12+1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head for prep　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for pobj　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for det　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for nsubj　for alpha = 0.01: 8-2 for 2/5 splits\n",
      "Head for amod　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for dobj　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for advmod　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for aux　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for poss　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for ccomp　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for mark　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for prt　for alpha = 0.01: 1-1 for 5/5 splits\n",
      "Head for prep　for alpha = 0.1: 6-2 for 5/5 splits\n",
      "Head for pobj　for alpha = 0.1: 8-11 for 3/5 splits\n",
      "Head for det　for alpha = 0.1: 8-11 for 5/5 splits\n",
      "Head for nsubj　for alpha = 0.1: 8-2 for 5/5 splits\n",
      "Head for amod　for alpha = 0.1: 1-1 for 5/5 splits\n",
      "Head for dobj　for alpha = 0.1: 8-10 for 4/5 splits\n",
      "Head for advmod　for alpha = 0.1: 8-4 for 4/5 splits\n",
      "Head for aux　for alpha = 0.1: 8-7 for 5/5 splits\n",
      "Head for poss　for alpha = 0.1: 8-3 for 5/5 splits\n",
      "Head for ccomp　for alpha = 0.1: 8-7 for 5/5 splits\n",
      "Head for mark　for alpha = 0.1: 1-1 for 5/5 splits\n",
      "Head for prt　for alpha = 0.1: 6-2 for 4/5 splits\n",
      "Head for prep　for alpha = 1: 6-2 for 3/5 splits\n",
      "Head for pobj　for alpha = 1: 1-2 for 3/5 splits\n",
      "Head for det　for alpha = 1: 8-11 for 5/5 splits\n",
      "Head for nsubj　for alpha = 1: 2-4 for 3/5 splits\n",
      "Head for amod　for alpha = 1: 1-9 for 4/5 splits\n",
      "Head for dobj　for alpha = 1: 8-10 for 2/5 splits\n",
      "Head for advmod　for alpha = 1: 4-3 for 5/5 splits\n",
      "Head for aux　for alpha = 1: 1-4 for 5/5 splits\n",
      "Head for poss　for alpha = 1: 1-8 for 5/5 splits\n",
      "Head for ccomp　for alpha = 1: 6-11 for 2/5 splits\n",
      "Head for mark　for alpha = 1: 5-7 for 2/5 splits\n",
      "Head for prt　for alpha = 1: 6-7 for 5/5 splits\n",
      "Head for prep　for alpha = 10: 8-5 for 4/5 splits\n",
      "Head for pobj　for alpha = 10: 8-5 for 2/5 splits\n",
      "Head for det　for alpha = 10: 8-11 for 5/5 splits\n",
      "Head for nsubj　for alpha = 10: 1-5 for 3/5 splits\n",
      "Head for amod　for alpha = 10: 1-9 for 4/5 splits\n",
      "Head for dobj　for alpha = 10: 4-6 for 4/5 splits\n",
      "Head for advmod　for alpha = 10: 4-3 for 2/5 splits\n",
      "Head for aux　for alpha = 10: 7-12 for 2/5 splits\n",
      "Head for poss　for alpha = 10: 1-8 for 4/5 splits\n",
      "Head for ccomp　for alpha = 10: 2-5 for 4/5 splits\n",
      "Head for mark　for alpha = 10: 6-5 for 5/5 splits\n",
      "Head for prt　for alpha = 10: 4-2 for 2/5 splits\n",
      "Head for prep　for alpha = 100: 8-5 for 3/5 splits\n",
      "Head for pobj　for alpha = 100: 8-5 for 3/5 splits\n",
      "Head for det　for alpha = 100: 8-11 for 4/5 splits\n",
      "Head for nsubj　for alpha = 100: 1-7 for 2/5 splits\n",
      "Head for amod　for alpha = 100: 1-9 for 2/5 splits\n",
      "Head for dobj　for alpha = 100: 4-6 for 4/5 splits\n",
      "Head for advmod　for alpha = 100: 4-3 for 4/5 splits\n",
      "Head for aux　for alpha = 100: 7-12 for 3/5 splits\n",
      "Head for poss　for alpha = 100: 1-8 for 4/5 splits\n",
      "Head for ccomp　for alpha = 100: 2-5 for 4/5 splits\n",
      "Head for mark　for alpha = 100: 6-5 for 3/5 splits\n",
      "Head for prt　for alpha = 100: 2-8 for 3/5 splits\n"
     ]
    }
   ],
   "source": [
    "out_list = []\n",
    "out_head = ['alpha','dep_rel','max_head','score','max_head for each split in CV']\n",
    "cv=5\n",
    "verbose = False\n",
    "for alpha in [0.01,0.1,1,10,100]:\n",
    "    #Smaller alpha for stronger regularization\n",
    "    for dep_rel in ['prep','pobj','det','nsubj','amod','dobj','advmod','aux','poss','ccomp','mark','prt']:\n",
    "        labels = CreateLabels(new_features,dep_rel)\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear',C=alpha)\n",
    "        scores,params = MyCrossValidation(new_vecs,labels,model,verbose,cv=cv)\n",
    "        important_head = collections.Counter([param.argmax() for param in params]).most_common()[0]\n",
    "        print(f'Head for {dep_rel}　for alpha = {alpha}: {ConvertHeadNotation(important_head[0])} for {important_head[1]}/5 splits')\n",
    "        out_list.append([alpha,dep_rel,ConvertHeadNotation(important_head[0]), np.mean(scores),\\\n",
    "                          ', '.join([ConvertHeadNotation(param.argmax()) for param in params])])\n",
    "pd.DataFrame(out_list,columns=out_head).to_csv('DepRelDecoding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
