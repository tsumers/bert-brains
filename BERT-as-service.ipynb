{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT server\n",
    "Quick notebook to set up + demo BERT-as-a-service: https://github.com/hanxiao/bert-as-service  \n",
    "\n",
    "\n",
    "**Note that the server needs an environment running TensorFlow < 2**, e.g. 1.15, and that you need python<3.7... so you'll need to run something like:\n",
    "```\n",
    "conda create --name bert_server python=3.7\n",
    "pip install tensorflow==1.15\n",
    "pip install bert-serving-server\n",
    "```\n",
    "\n",
    "Downloaded BERT-Base, Uncased:  \n",
    "https://github.com/google-research/bert#pre-trained-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Settings\n",
    "\n",
    "Use BERT-server defaults (REDUCE_MEAN on second-to-last layer)  \n",
    "https://github.com/hanxiao/bert-as-service#q-how-do-you-get-the-fixed-representation-did-you-do-pooling-or-something\n",
    "\n",
    "\n",
    "**START BERT SERVER AS FOLLOWS**:\n",
    "```\n",
    "bert-serving-start -model_dir ~/src/data/uncased_L-12_H-768_A-12/\n",
    "```\n",
    "\n",
    "**Then start the client**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = bc.encode([\"Here's a test sentence\", \"here's a second test sentence which is longer and more mysterious\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Layer?\n",
    "The default BERT implementation uses the second-to-last-layer. \n",
    "\n",
    "https://github.com/hanxiao/bert-as-service#q-bert-has-1224-layers-so-which-layer-are-you-talking-about\n",
    "\n",
    "So here we keep `REDUCE_MEAN` as the pooling strategy, but go shallower: BERT's middle and early layers.\n",
    "\n",
    "#### Third-to-last layer  \n",
    "**Restart the BERT server as follows:**\n",
    "```\n",
    "bert-serving-start -pooling_layer -3 -model_dir ~/src/data/uncased_L-12_H-768_A-12/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlier_layer = bc.encode([\"Cheesecake\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "Re-start the BERT server with _no pooling_. Here, I also use a very early layer (4).  \n",
    "\n",
    "See the docs:  \n",
    "https://github.com/hanxiao/bert-as-service#getting-elmo-like-contextual-word-embedding\n",
    "\n",
    "**Re-start BERT server:**\n",
    "```\n",
    "bert-serving-start -show_tokens_to_client -pooling_strategy NONE -pooling_layer -8 -model_dir ~/src/data/uncased_L-12_H-768_A-12/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_tokens =  bc.encode([\"here's a second test sentence which is longer and more mysterious\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(many_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
