{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIMULUS = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STIMULUS == '21st_year':\n",
    "    with open('data/21st_year/21st_year.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        file = [row for row in reader]\n",
    "        head = file[1]\n",
    "        text = file[2:]\n",
    "    sentences = [row[head.index('Sentence')].replace('\\xa0', ' ') for row in text]\n",
    "    TR_ids = [row[head.index('Index')] for row in text]\n",
    "    \n",
    "    doc = nlp.pipe(sentences)\n",
    "    ling_features = []\n",
    "    for TR ,line in zip(TR_ids, doc):\n",
    "        for token in line:\n",
    "            if token.pos_ != 'SPACE':\n",
    "                ling_features.append([TR,token.text,token.lemma_,token.pos_,token.tag_,token.dep_,token.head.text,abs(token.i-token.head.i)])\n",
    "\n",
    "elif STIMULUS in ['slumlordreach','black']:\n",
    "    with open(f'data/{STIMULUS}/align.csv','r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        token_list = [row[0] for row in reader]\n",
    "    doc = nlp(' '.join(token_list))\n",
    "    sent_id = 0\n",
    "    ling_features = []\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.pos_ != 'SPACE':\n",
    "                ling_features.append([sent_id,token.text,token.lemma_,token.pos_,token.tag_,token.dep_,token.head.text,abs(token.i-token.head.i)])\n",
    "        sent_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features = pd.DataFrame(ling_features,columns=[\"index\",\"token\",\"lemma\",\"pos\",\"tag\",\"dep_rel\",\"dep_head\",\"dep_distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep_rel</th>\n",
       "      <th>dep_head</th>\n",
       "      <th>dep_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So</td>\n",
       "      <td>so</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>was</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>was</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>was</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>junior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>junior</td>\n",
       "      <td>junior</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>was</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>170</td>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WP</td>\n",
       "      <td>dobj</td>\n",
       "      <td>Thank</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>170</td>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Thank</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>170</td>\n",
       "      <td>do</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>aux</td>\n",
       "      <td>Thank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>170</td>\n",
       "      <td>Thank</td>\n",
       "      <td>thank</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>pcomp</td>\n",
       "      <td>at</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>170</td>\n",
       "      <td>you</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>dobj</td>\n",
       "      <td>Thank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   token   lemma   pos  tag dep_rel dep_head  dep_distance\n",
       "0         0      So      so   ADV   RB  advmod      was             2\n",
       "1         0       I  -PRON-  PRON  PRP   nsubj      was             1\n",
       "2         0     was      be   AUX  VBD    ROOT      was             0\n",
       "3         0       a       a   DET   DT     det   junior             1\n",
       "4         0  junior  junior  NOUN   NN    attr      was             2\n",
       "...     ...     ...     ...   ...  ...     ...      ...           ...\n",
       "1604    170    what    what  PRON   WP    dobj    Thank             3\n",
       "1605    170       I  -PRON-  PRON  PRP   nsubj    Thank             2\n",
       "1606    170      do      do   AUX  VBP     aux    Thank             1\n",
       "1607    170   Thank   thank  VERB  VBP   pcomp       at             4\n",
       "1608    170     you  -PRON-  PRON  PRP    dobj    Thank             1\n",
       "\n",
       "[1609 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ling_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_features.to_csv(f'data/{STIMULUS}/ling_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align with the TRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/{STIMULUS}/ling_features.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    file = [row for row in reader]\n",
    "    head = file[0]\n",
    "    text = file[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/{STIMULUS}/tr_tokens.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    TR_file = [row for row in reader]\n",
    "    TR_head = TR_file[0]\n",
    "    TR_text = TR_file[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STIMULUS == '21st_year':\n",
    "    #TRs that include the same tokens twice\n",
    "    double_count_dict = {'182': 'the','288':'the','399':'to','413':'do','439':'is','461':'a','502':'the','515':'it','525':'Every','630':'she','687':'the',\\\n",
    "                        '693':'her','707':'of','815':'go','828':'to','869':'we','898':'ticket','983':'in','1310':'her','1377':'the','1390':'her','1398':'\"','1439':'“',\\\n",
    "                         '1461':'there','1528':'you','1579':'the','1800':'of','1821':'his','1982':'close','2039':'angry','2183':'the','2185':'than'}\n",
    "    #TRs part of which appear in the previous TR\n",
    "    bridging_TRs = ['A1.7','B1.19','A2.5','A3.12','A5.20','A6.9','B6.4','A7.6','A7.13','A7.16',\\\n",
    "                    'B7.2','B10.8','B11.9','B11.16','A12.5','B13.24','B14.12','C1.2','C2.5','C12.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STIMULUS == '21st_year':\n",
    "    current_id = 0\n",
    "    new_data = []\n",
    "    for TR_line in TR_text:\n",
    "        TR_tokens = TR_line[TR_head.index('tokens')]\n",
    "        TR_index = TR_line[TR_head.index('index')]\n",
    "        if TR_tokens != \"\":\n",
    "            TR_tokens = TR_tokens.replace('\\xa0', ' ')\n",
    "            token_list = [token.text for token in nlp(TR_tokens)]\n",
    "            lemma_list = []\n",
    "            pos_list = []\n",
    "            tag_list = []\n",
    "            dep_rel_list = []\n",
    "            dep_head_list = []\n",
    "            dep_dist_list = []\n",
    "            check_list = []\n",
    "            double_count = 0\n",
    "            triple_count = 0\n",
    "            while text[current_id][head.index('token')] in token_list\\\n",
    "            and (text[current_id][head.index('index')] == TR_index\\\n",
    "            or text[current_id][head.index('index')] in bridging_TRs)\\\n",
    "            and double_count != 2 and triple_count != 3:\n",
    "                if TR_line[TR_head.index('tr')] in list(double_count_dict.keys()):\n",
    "                    if text[current_id][head.index('token')] == double_count_dict[TR_line[TR_head.index('tr')]]:\n",
    "                        double_count += 1\n",
    "                if TR_line[TR_head.index('tr')] == '534' and text[current_id][head.index('token')] == '\"':\n",
    "                    triple_count += 1\n",
    "                line = text[current_id]\n",
    "                lemma_list.append(line[head.index('lemma')])\n",
    "                pos_list.append(line[head.index('pos')])\n",
    "                tag_list.append(line[head.index('tag')])\n",
    "                dep_rel_list.append(line[head.index('dep_rel')])\n",
    "                dep_head_list.append(line[head.index('dep_head')])\n",
    "                dep_dist_list.append(line[head.index('dep_distance')])\n",
    "                check_list.append(line[head.index('token')])\n",
    "                if current_id == len(text)-1:\n",
    "                    break\n",
    "                current_id += 1\n",
    "                if double_count == 2 or triple_count == 3:\n",
    "                    current_id -= 1\n",
    "                    del lemma_list[-1], pos_list[-1], tag_list[-1], dep_rel_list[-1], dep_head_list[-1], dep_dist_list[-1]\n",
    "            TR_line.extend([lemma_list,pos_list,tag_list,dep_rel_list,dep_head_list,dep_dist_list])\n",
    "\n",
    "            #Sanity check#\n",
    "            if TR_line[TR_head.index('tr')] not in ['539','935','2161']:\n",
    "                if check_list[0] != token_list[0]:\n",
    "                    print(f'Error in {TR_line}')\n",
    "\n",
    "            new_data.append(TR_line)\n",
    "        else:\n",
    "            TR_line.extend([[],[],[],[],[],[]])\n",
    "            new_data.append(TR_line)\n",
    "    TR_head.extend([\"lemma\",\"pos\",\"tag\",\"dep_rel\",\"dep_head\",\"dep_distance\"])\n",
    "    new_data = pd.DataFrame(new_data,columns=TR_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STIMULUS in ['slumlordreach','black']:\n",
    "    current_id = 0\n",
    "    new_data = []\n",
    "    for TR_line in TR_text:\n",
    "        TR_tokens = TR_line[TR_head.index('tokens')]\n",
    "        lemma_list = []\n",
    "        pos_list = []\n",
    "        tag_list = []\n",
    "        dep_rel_list = []\n",
    "        dep_head_list = []\n",
    "        dep_dist_list = []\n",
    "        if TR_tokens != \"\":\n",
    "            token_list = [token.text for token in nlp(TR_tokens)]\n",
    "            for token in token_list:\n",
    "                line = text[current_id]\n",
    "                lemma_list.append(line[head.index('lemma')])\n",
    "                pos_list.append(line[head.index('pos')])\n",
    "                tag_list.append(line[head.index('tag')])\n",
    "                dep_rel_list.append(line[head.index('dep_rel')])\n",
    "                dep_head_list.append(line[head.index('dep_head')])\n",
    "                dep_dist_list.append(line[head.index('dep_distance')])\n",
    "                current_id += 1\n",
    "        TR_line.extend([lemma_list,pos_list,tag_list,dep_rel_list,dep_head_list,dep_dist_list])\n",
    "        new_data.append(TR_line)\n",
    "    TR_head.extend([\"lemma\",\"pos\",\"tag\",\"dep_rel\",\"dep_head\",\"dep_distance\"])\n",
    "    new_data = pd.DataFrame(new_data,columns=TR_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr</th>\n",
       "      <th>start_ts</th>\n",
       "      <th>end_ts</th>\n",
       "      <th>tr</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>tr_shift</th>\n",
       "      <th>prev_tr</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep_rel</th>\n",
       "      <th>dep_head</th>\n",
       "      <th>dep_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0</td>\n",
       "      <td>So I</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[so, -PRON-]</td>\n",
       "      <td>[ADV, PRON]</td>\n",
       "      <td>[RB, PRP]</td>\n",
       "      <td>[advmod, nsubj]</td>\n",
       "      <td>[was, was]</td>\n",
       "      <td>[2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1</td>\n",
       "      <td>was a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[be, a]</td>\n",
       "      <td>[AUX, DET]</td>\n",
       "      <td>[VBD, DT]</td>\n",
       "      <td>[ROOT, det]</td>\n",
       "      <td>[was, junior]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.46</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2</td>\n",
       "      <td>junior in college</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[junior, in, college]</td>\n",
       "      <td>[NOUN, ADP, NOUN]</td>\n",
       "      <td>[NN, IN, NN]</td>\n",
       "      <td>[attr, prep, pobj]</td>\n",
       "      <td>[was, junior, in]</td>\n",
       "      <td>[2, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.59</td>\n",
       "      <td>3</td>\n",
       "      <td>when I got my</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[when, -PRON-, get, -PRON-]</td>\n",
       "      <td>[ADV, PRON, VERB, DET]</td>\n",
       "      <td>[WRB, PRP, VBD, PRP$]</td>\n",
       "      <td>[advmod, nsubj, advcl, poss]</td>\n",
       "      <td>[got, got, was, paying]</td>\n",
       "      <td>[2, 1, 7, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.34</td>\n",
       "      <td>4</td>\n",
       "      <td>first</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[first]</td>\n",
       "      <td>[ADJ]</td>\n",
       "      <td>[JJ]</td>\n",
       "      <td>[amod]</td>\n",
       "      <td>[paying]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>529</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>529</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>530</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>530</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>531</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>532</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>799.8100000000002</td>\n",
       "      <td>799.83</td>\n",
       "      <td>533</td>\n",
       "      <td>you</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>[-PRON-]</td>\n",
       "      <td>[PRON]</td>\n",
       "      <td>[PRP]</td>\n",
       "      <td>[dobj]</td>\n",
       "      <td>[Thank]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tr           start_ts  end_ts   tr             tokens n_tokens tr_shift  \\\n",
       "0      0               0.24    1.26    0               So I      2.0            \n",
       "1      1               1.96    2.45    1              was a      2.0      1.0   \n",
       "2      2               2.46     4.2    2  junior in college      3.0      1.0   \n",
       "3      3               4.79    5.59    3      when I got my      4.0      1.0   \n",
       "4      4               5.61    6.34    4              first      1.0      1.0   \n",
       "..   ...                ...     ...  ...                ...      ...      ...   \n",
       "529  529                             529                                        \n",
       "530  530                             530                                        \n",
       "531  531                             531                                        \n",
       "532  532                             532                                        \n",
       "533  533  799.8100000000002  799.83  533                you      1.0      5.0   \n",
       "\n",
       "    prev_tr                        lemma                     pos  \\\n",
       "0                           [so, -PRON-]             [ADV, PRON]   \n",
       "1       0.0                      [be, a]              [AUX, DET]   \n",
       "2       1.0        [junior, in, college]       [NOUN, ADP, NOUN]   \n",
       "3       2.0  [when, -PRON-, get, -PRON-]  [ADV, PRON, VERB, DET]   \n",
       "4       3.0                      [first]                   [ADJ]   \n",
       "..      ...                          ...                     ...   \n",
       "529                                   []                      []   \n",
       "530                                   []                      []   \n",
       "531                                   []                      []   \n",
       "532                                   []                      []   \n",
       "533   528.0                     [-PRON-]                  [PRON]   \n",
       "\n",
       "                       tag                       dep_rel  \\\n",
       "0                [RB, PRP]               [advmod, nsubj]   \n",
       "1                [VBD, DT]                   [ROOT, det]   \n",
       "2             [NN, IN, NN]            [attr, prep, pobj]   \n",
       "3    [WRB, PRP, VBD, PRP$]  [advmod, nsubj, advcl, poss]   \n",
       "4                     [JJ]                        [amod]   \n",
       "..                     ...                           ...   \n",
       "529                     []                            []   \n",
       "530                     []                            []   \n",
       "531                     []                            []   \n",
       "532                     []                            []   \n",
       "533                  [PRP]                        [dobj]   \n",
       "\n",
       "                    dep_head  dep_distance  \n",
       "0                 [was, was]        [2, 1]  \n",
       "1              [was, junior]        [0, 1]  \n",
       "2          [was, junior, in]     [2, 1, 1]  \n",
       "3    [got, got, was, paying]  [2, 1, 7, 2]  \n",
       "4                   [paying]           [1]  \n",
       "..                       ...           ...  \n",
       "529                       []            []  \n",
       "530                       []            []  \n",
       "531                       []            []  \n",
       "532                       []            []  \n",
       "533                  [Thank]           [1]  \n",
       "\n",
       "[534 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(f'data/{STIMULUS}/tr_tokens_new.csv')\n",
    "new_data.to_pickle(f'data/{STIMULUS}/tr_tokens_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
